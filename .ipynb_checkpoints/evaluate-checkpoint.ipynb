{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "69ddf03c",
   "metadata": {},
   "source": [
    "# 1. Import All Necessary Libraries and Create File Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f3f7005",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "# Plotting\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "import glob\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "import math\n",
    "import datetime\n",
    "from keras import backend as K\n",
    "import tensorboard as tb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26c4f307",
   "metadata": {},
   "outputs": [],
   "source": [
    "# folder path or file path constants that will be used in this project\n",
    "# Root Directory (between 'F:' or 'D:'' depends on the external drive)\n",
    "ROOT = \"D:\\\\\"\n",
    "\n",
    "# Folder inside D:\\\\wildfire-sumatera-dataset\n",
    "WILDFIRE_SUMATERA_DATASET_FOLDER_PATH = os.path.join(ROOT, 'wildfire-sumatera-dataset')\n",
    "\n",
    "\n",
    "# Folders and metadatas inside D:\\\\wildfire-sumatera-dataset\n",
    "WILDFIRE_SUMATERA_GEOTIFF_FOLDER_PATH = os.path.join(WILDFIRE_SUMATERA_DATASET_FOLDER_PATH, 'wildfire-sumatera-geotiff')\n",
    "WILDFIRE_SUMATERA_IMAGE_FOLDER_PATH = os.path.join(WILDFIRE_SUMATERA_DATASET_FOLDER_PATH, 'wildfire-sumatera-image')\n",
    "WILDFIRE_SUMATERA_IMAGE_MASK_FOLDER_PATH = os.path.join(WILDFIRE_SUMATERA_DATASET_FOLDER_PATH, 'wildfire-sumatera-image-mask')\n",
    "WILDFIRE_SUMATERA_IMAGE_MASK_TFRECORD_FOLDER_PATH = os.path.join(WILDFIRE_SUMATERA_DATASET_FOLDER_PATH, 'wildfire-sumatera-image-mask-tfrecords')\n",
    "\n",
    "# Files (.csv) and metadatas inside D:\\\\wildfire-sumatera-dataset\n",
    "METADATA_LANDSAT_8_FILE_PATH = os.path.join(WILDFIRE_SUMATERA_DATASET_FOLDER_PATH, 'metadata_landsat_8.csv')\n",
    "METADATA_SENTINEL_2_FILE_PATH = os.path.join(WILDFIRE_SUMATERA_DATASET_FOLDER_PATH, 'metadata_sentinel_2.csv')\n",
    "\n",
    "# Folders inside D:\\\\wildfire-sumatera-dataset\\\\wildfire-sumatera-geotiff\n",
    "SENTINEL_2_GEOTIFF_FOLDER_PATH = os.path.join(WILDFIRE_SUMATERA_GEOTIFF_FOLDER_PATH, 'sentinel-2')\n",
    "LANDSAT_8_GEOTIFF_FOLDER_PATH = os.path.join(WILDFIRE_SUMATERA_GEOTIFF_FOLDER_PATH, 'landsat-8')\n",
    "\n",
    "# Folders inside D:\\\\wildfire-sumatera-dataset\\\\wildfire-sumatera-image\n",
    "SENTINEL_2_IMAGE_FOLDER_PATH = os.path.join(WILDFIRE_SUMATERA_IMAGE_FOLDER_PATH, 'sentinel-2')\n",
    "LANDSAT_8_IMAGE_FOLDER_PATH = os.path.join(WILDFIRE_SUMATERA_IMAGE_FOLDER_PATH, 'landsat-8')\n",
    "\n",
    "# Folders inside D:\\\\wildfire-sumatera-dataset\\\\wildfire-sumatera-geotiff\\\\landsat-8\n",
    "LANDSAT_8_PREFIRE_GEOTIFF_FOLDER_PATH = os.path.join(LANDSAT_8_GEOTIFF_FOLDER_PATH, 'prefire')\n",
    "LANDSAT_8_POSTFIRE_GEOTIFF_FOLDER_PATH = os.path.join(LANDSAT_8_GEOTIFF_FOLDER_PATH, 'postfire')\n",
    "\n",
    "# Folders inside D:\\\\wildfire-sumatera-dataset\\\\wildfire-sumatera-geotiff\\\\sentinel-2\n",
    "SENTINEL_2_PREFIRE_GEOTIFF_FOLDER_PATH = os.path.join(SENTINEL_2_GEOTIFF_FOLDER_PATH, 'prefire')\n",
    "SENTINEL_2_POSTFIRE_GEOTIFF_FOLDER_PATH = os.path.join(SENTINEL_2_GEOTIFF_FOLDER_PATH, 'postfire')\n",
    "\n",
    "# Folders inside D:\\\\wildfire-sumatera-dataset\\\\wildfire-sumatera-image-mask\n",
    "SENTINEL_2_IMAGE_MASK_FOLDER_PATH = os.path.join(WILDFIRE_SUMATERA_IMAGE_MASK_FOLDER_PATH, 'sentinel-2')\n",
    "LANDSAT_8_IMAGE_MASK_FOLDER_PATH = os.path.join(WILDFIRE_SUMATERA_IMAGE_MASK_FOLDER_PATH, 'landsat-8')\n",
    "\n",
    "# Folders inside\n",
    "SENTINEL_2_B12_B8_B2_IMAGE_MASK_TFRECORD_FOLDER_PATH = os.path.join(WILDFIRE_SUMATERA_IMAGE_MASK_TFRECORD_FOLDER_PATH, 'sentinel-2_b12_b8_b2')\n",
    "LANDSAT_8_B7_B5_B2_IMAGE_MASK_TFRECORD_FOLDER_PATH = os.path.join(WILDFIRE_SUMATERA_IMAGE_MASK_TFRECORD_FOLDER_PATH, 'landsat-8_b7_b5_b2')\n",
    "SENTINEL_2_B4_B3_B2_IMAGE_MASK_TFRECORD_FOLDER_PATH = os.path.join(WILDFIRE_SUMATERA_IMAGE_MASK_TFRECORD_FOLDER_PATH, 'sentinel-2_b4_b3_b2')\n",
    "LANDSAT_8_B4_B3_B2_IMAGE_MASK_TFRECORD_FOLDER_PATH = os.path.join(WILDFIRE_SUMATERA_IMAGE_MASK_TFRECORD_FOLDER_PATH, 'landsat-8_b4_b3_b2')\n",
    "\n",
    "\n",
    "dirs = [\n",
    "    WILDFIRE_SUMATERA_DATASET_FOLDER_PATH,\n",
    "    WILDFIRE_SUMATERA_GEOTIFF_FOLDER_PATH, \n",
    "    WILDFIRE_SUMATERA_IMAGE_FOLDER_PATH,\n",
    "    WILDFIRE_SUMATERA_IMAGE_MASK_FOLDER_PATH,\n",
    "    WILDFIRE_SUMATERA_IMAGE_MASK_TFRECORD_FOLDER_PATH,\n",
    "    \n",
    "    SENTINEL_2_GEOTIFF_FOLDER_PATH, \n",
    "    LANDSAT_8_GEOTIFF_FOLDER_PATH,\n",
    "    SENTINEL_2_IMAGE_FOLDER_PATH,\n",
    "    LANDSAT_8_IMAGE_FOLDER_PATH,\n",
    "    \n",
    "    LANDSAT_8_PREFIRE_GEOTIFF_FOLDER_PATH,\n",
    "    LANDSAT_8_POSTFIRE_GEOTIFF_FOLDER_PATH,\n",
    "    SENTINEL_2_PREFIRE_GEOTIFF_FOLDER_PATH,\n",
    "    SENTINEL_2_POSTFIRE_GEOTIFF_FOLDER_PATH,\n",
    "    \n",
    "    SENTINEL_2_IMAGE_MASK_FOLDER_PATH,\n",
    "    LANDSAT_8_IMAGE_MASK_FOLDER_PATH,\n",
    "    \n",
    "    SENTINEL_2_B12_B8_B2_IMAGE_MASK_TFRECORD_FOLDER_PATH,\n",
    "    LANDSAT_8_B7_B5_B2_IMAGE_MASK_TFRECORD_FOLDER_PATH,\n",
    "    SENTINEL_2_B4_B3_B2_IMAGE_MASK_TFRECORD_FOLDER_PATH,\n",
    "    LANDSAT_8_B4_B3_B2_IMAGE_MASK_TFRECORD_FOLDER_PATH,\n",
    "\n",
    "]\n",
    "\n",
    "for dir_ in dirs:\n",
    "    if not os.path.exists(dir_):\n",
    "        os.mkdir(dir_)\n",
    "        print(f\"{dir_} has been created\")\n",
    "    else:\n",
    "        print(f\"{dir_} already exist\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50e5223a",
   "metadata": {},
   "source": [
    "# 2. Import Data from Tensorboard Dev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a747b106",
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_id = \"VCKTPVIbSlqz8MsaK1REpg\"\n",
    "experiment = tb.data.experimental.ExperimentFromDev(experiment_id)\n",
    "df_b4_b3_b2 = experiment.get_scalars()\n",
    "\n",
    "experiment_id = \"vRHXyHxDR82W5GG7a0qv5Q\"\n",
    "experiment = tb.data.experimental.ExperimentFromDev(experiment_id)\n",
    "df_b7_b5_b12_b8_b2 = experiment.get_scalars()\n",
    "\n",
    "df = pd.concat([df_b4_b3_b2, df_b7_b5_b12_b8_b2], ignore_index=True)\n",
    "df.to_csv(\"logs.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1d49371",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"logs.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f75445a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df= df.loc[~(df.tag.str.contains('vs'))]\n",
    "df.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27587292",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82137cfa",
   "metadata": {},
   "source": [
    "## Create New Column for Each Hyperparameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fdcc932",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# satellite_band column\n",
    "satellite_band_arr = []\n",
    "for index, row in df.iterrows():\n",
    "    if 'landsat_8_b4_b3_b2' in row.run:\n",
    "        satellite_band_arr.append('landsat_8_b4_b3_b2')\n",
    "    elif 'landsat_8_b7_b5_b2' in row.run:\n",
    "        satellite_band_arr.append('landsat_8_b7_b5_b2')\n",
    "    elif 'sentinel_2_b4_b3_b2' in row.run:\n",
    "        satellite_band_arr.append('sentinel_2_b4_b3_b2')\n",
    "    elif 'sentinel_2_b12_b8_b2' in row.run:\n",
    "        satellite_band_arr.append('sentinel_2_b12_b8_b2')\n",
    "\n",
    "df = df.assign(satellite_band=satellite_band_arr)\n",
    "        \n",
    "count = 0\n",
    "for index, row in df.iterrows():\n",
    "    if str(row.satellite_band) in row.run:\n",
    "        count+=1\n",
    "print('operation is a success' if len(df) == count else 'operation failed')\n",
    "\n",
    "# type_run column\n",
    "df = df.assign(type_run=df.run.apply(\n",
    "    lambda x: 'validation' if x.endswith('validation') else 'train').to_list())\n",
    "\n",
    "count = 0\n",
    "for index, row in df.iterrows():\n",
    "    if str(row.type_run) in row.run:\n",
    "        count+=1\n",
    "print('operation is a success' if len(df) == count else 'operation failed')\n",
    "\n",
    "# optimizer column\n",
    "df = df.assign(opt=df.run.apply(lambda x: 'adam' if 'adam' in x else 'rmsprop').to_list())\n",
    "count = 0\n",
    "for index, row in df.iterrows():\n",
    "    if str(row.opt) in row.run:\n",
    "        count+=1\n",
    "print('operation is a success' if len(df) == count else 'operation failed')\n",
    "\n",
    "# learning_rate column\n",
    "df = df.assign(lr=df.run.apply(lambda x: 0.001 if '0.001' in x else 0.01).to_list())\n",
    "count = 0\n",
    "for index, row in df.iterrows():\n",
    "    if str(row.lr) in row.run:\n",
    "        count+=1\n",
    "print('operation is a success' if len(df) == count else 'operation failed')\n",
    "\n",
    "# batch column\n",
    "batch_arr = []\n",
    "for index, row in df.iterrows():\n",
    "    if 'batch_64' in row.run:\n",
    "        batch_arr.append(64)\n",
    "    elif 'batch_32' in row.run:\n",
    "        batch_arr.append(32)\n",
    "    elif 'batch_16' in row.run:\n",
    "        batch_arr.append(16)\n",
    "\n",
    "df = df.assign(batch=batch_arr)\n",
    "count = 0\n",
    "for index, row in df.iterrows():\n",
    "    if str(row.batch) in row.run:\n",
    "        count+=1\n",
    "print('operation is a success' if len(df) == count else 'operation failed')\n",
    "\n",
    "# starting filters column\n",
    "df = df.assign(start_filter=df.run.apply(lambda x: 32 if 'filters_32' in x else 16).to_list())\n",
    "count = 0\n",
    "for index, row in df.iterrows():\n",
    "    if str(row.start_filter) in row.run:\n",
    "        count+=1\n",
    "print('operation is a success' if len(df) == count else 'operation failed')\n",
    "\n",
    "# image size column\n",
    "size_arr = []\n",
    "for index, row in df.iterrows():\n",
    "    if 'size_176' in row.run:\n",
    "        size_arr.append(176)\n",
    "    elif 'size_144' in row.run:\n",
    "        size_arr.append(144)\n",
    "    elif 'size_112' in row.run:\n",
    "        size_arr.append(112)\n",
    "\n",
    "df = df.assign(img_size=size_arr)\n",
    "count = 0\n",
    "for index, row in df.iterrows():\n",
    "    if str(row.img_size) in row.run:\n",
    "        count+=1\n",
    "print('operation is a success' if len(df) == count else 'operation failed')\n",
    "\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68c1c2ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_landsat_b4_b3_b2 = df.loc[df.satellite_band=='landsat_8_b4_b3_b2']\n",
    "df_sentinel_b4_b3_b2 = df.loc[df.satellite_band=='sentinel_2_b4_b3_b2']\n",
    "df_landsat_b7_b5_b2 = df.loc[df.satellite_band=='landsat_8_b7_b5_b2']\n",
    "df_sentinel_b12_b8_b2 = df.loc[df.satellite_band=='sentinel_2_b12_b8_b2']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08c5d6ac",
   "metadata": {},
   "source": [
    "# Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bfde9ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_metric_for_optimizer(metric, band_title, hue, data_for_plot):\n",
    "    data_adam_train = data_for_plot.loc[\n",
    "        (data_for_plot.run.str.endswith('train')) & \n",
    "        (data_for_plot.run.str.contains('adam')) & \n",
    "        (data_for_plot.tag==metric)]\n",
    "\n",
    "    data_adam_val= data_for_plot.loc[\n",
    "        (data_for_plot.run.str.endswith('validation')) & \n",
    "        (data_for_plot.run.str.contains('adam')) & \n",
    "        (data_for_plot.tag==metric)]\n",
    "    \n",
    "    data_rmsprop_train = data_for_plot.loc[\n",
    "        (data_for_plot.run.str.endswith('train')) & \n",
    "        (data_for_plot.run.str.contains('rmsprop')) & \n",
    "        (data_for_plot.tag==metric)]\n",
    "    \n",
    "    data_rmsprop_val = data_for_plot.loc[\n",
    "        (data_for_plot.run.str.endswith('validation')) & \n",
    "        (data_for_plot.run.str.contains('rmsprop')) & \n",
    "        (data_for_plot.tag==metric)]\n",
    "    \n",
    "    fig, ax = plt.subplots(nrows=2, ncols=2, figsize=(20, 15), sharey=True)\n",
    "\n",
    "    ax[0][0].grid()\n",
    "    ax[0][0].set_xticks(np.arange(data_adam_train.step.min(), data_adam_train.step.max()+1, 1))\n",
    "    ax[0][0].set_yticks(np.arange(math.floor(data_adam_train.value.min()), \n",
    "                                  math.floor(data_adam_train.value.max()+1), 0.02))\n",
    "    sns.lineplot(data=data_adam_train, x='step', y='value', hue=hue, ax=ax[0][0], palette='tab10', ci=None)\\\n",
    "        .set_title('Mean of {} for U-Net Model with {} Optimizer (train) and Band {}'\\\n",
    "                   .format(metric, 'adam'.capitalize(), band_title))\n",
    "    ax[0][0].legend(loc='upper left')\n",
    "    \n",
    "    ax[0][1].grid()\n",
    "    ax[0][1].set_xticks(np.arange(data_adam_val.step.min(), data_adam_val.step.max()+1, 1))\n",
    "    ax[0][1].set_yticks(np.arange(math.floor(data_adam_val.value.min()), \n",
    "                                  math.floor(data_adam_val.value.max()+1), 0.02))\n",
    "    sns.lineplot(data=data_adam_val, x='step', y='value', hue=hue, ax=ax[0][1], palette='tab10', ci=None)\\\n",
    "        .set_title('Mean of {} for U-Net Model with {} Optimizer (validation) and Band {}'\\\n",
    "                   .format(metric, 'adam'.capitalize(), band_title))\n",
    "    ax[0][1].legend(loc='upper left')\n",
    "    \n",
    "    ax[1][0].grid()\n",
    "    ax[1][0].set_xticks(np.arange(data_rmsprop_train.step.min(), data_rmsprop_train.step.max()+1, 1))\n",
    "    ax[1][0].set_yticks(np.arange(math.floor(data_rmsprop_train.value.min()), \n",
    "                                  math.floor(data_rmsprop_train.value.max()+1), 0.02))\n",
    "    sns.lineplot(data=data_rmsprop_train, x='step', y='value', hue=hue, ax=ax[1][0], palette='tab10', ci=None)\\\n",
    "        .set_title('Mean of {} for U-Net Model with {} Optimizer (train) and Band {}'\\\n",
    "                   .format(metric, 'rmsprop'.capitalize(), band_title))\n",
    "    ax[1][0].legend(loc='upper left')\n",
    "    \n",
    "    ax[1][1].grid()\n",
    "    ax[1][1].set_xticks(np.arange(data_rmsprop_val.step.min(), \n",
    "                                  data_rmsprop_val.step.max()+1, 1))\n",
    "    ax[1][1].set_yticks(np.arange(math.floor(data_rmsprop_val.value.min()), \n",
    "                                  math.floor(data_rmsprop_val.value.max()+1), 0.02))\n",
    "    sns.lineplot(data=data_rmsprop_val, x='step', y='value', hue=hue, ax=ax[1][1], palette='tab10', ci=None)\\\n",
    "        .set_title('Mean of {} for U-Net Model with {} Optimizer (validation) and Band {}'\\\n",
    "                   .format(metric, 'rmsprop'.capitalize(), band_title))\n",
    "    ax[1][1].legend(loc='upper left')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38342510",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_loss(metric, band_title, hue, data_for_plot):\n",
    "    data_adam_train = data_for_plot.loc[\n",
    "        (data_for_plot.run.str.endswith('train')) & \n",
    "        (data_for_plot.run.str.contains('adam')) & \n",
    "        (data_for_plot.tag==metric)]\n",
    "\n",
    "    data_adam_val= data_for_plot.loc[\n",
    "        (data_for_plot.run.str.endswith('validation')) & \n",
    "        (data_for_plot.run.str.contains('adam')) & \n",
    "        (data_for_plot.tag==metric)]\n",
    "    \n",
    "    data_rmsprop_train = data_for_plot.loc[\n",
    "        (data_for_plot.run.str.endswith('train')) & \n",
    "        (data_for_plot.run.str.contains('rmsprop')) & \n",
    "        (data_for_plot.tag==metric)]\n",
    "    \n",
    "    data_rmsprop_val = data_for_plot.loc[\n",
    "        (data_for_plot.run.str.endswith('validation')) & \n",
    "        (data_for_plot.run.str.contains('rmsprop')) & \n",
    "        (data_for_plot.tag==metric)]\n",
    "    \n",
    "    fig, ax = plt.subplots(nrows=2, ncols=2, figsize=(20, 15), sharey=True)\n",
    "    \n",
    "    ax[0][0].grid()\n",
    "    ax[0][0].set_xticks(np.arange(data_adam_train.step.min(), data_adam_train.step.max()+1, 1))\n",
    "    ax[0][0].set_yticks(np.arange(math.floor(data_adam_train.value.min()), 1, 0.02))\n",
    "    ax[0][0].set_ylim([0.1, 0.6])\n",
    "    sns.lineplot(data=data_adam_train, x='step', y='value', hue=hue, ax=ax[0][0], palette='tab10', ci=None)\\\n",
    "        .set_title('Mean of {} for U-Net Model with {} Optimizer (train) and Band {}'.format(metric, 'adam'.capitalize(), band_title))\n",
    "    ax[0][0].legend(loc='upper left')\n",
    "    \n",
    "    ax[0][1].grid()\n",
    "    ax[0][1].set_xticks(np.arange(data_adam_val.step.min(), data_adam_val.step.max()+1, 1))\n",
    "    ax[0][1].set_yticks(np.arange(math.floor(data_adam_val.value.min()), 1, 0.02))\n",
    "    ax[0][1].set_ylim([0.1, 0.6])\n",
    "    sns.lineplot(data=data_adam_val, x='step', y='value', hue=hue, ax=ax[0][1], palette='tab10', ci=None)\\\n",
    "        .set_title('Mean of {} for U-Net Model with {} Optimizer (validation) and Band {}'.format(metric, 'adam'.capitalize(), band_title))\n",
    "    ax[0][1].legend(loc='upper left')\n",
    "    \n",
    "    ax[1][0].grid()\n",
    "    ax[1][0].set_xticks(np.arange(data_rmsprop_train.step.min(), data_rmsprop_train.step.max()+1, 1))\n",
    "    ax[1][0].set_yticks(np.arange(math.floor(data_rmsprop_train.value.min()), 1, 0.02))\n",
    "    ax[1][0].set_ylim([0.1, 0.6])\n",
    "    sns.lineplot(data=data_rmsprop_train, x='step', y='value', hue=hue, ax=ax[1][0], palette='tab10', ci=None)\\\n",
    "        .set_title('Mean of {} for U-Net Model with {} Optimizer (train) and Band {}'.format(metric, 'rmsprop'.capitalize(), band_title))\n",
    "    ax[1][0].legend(loc='upper left')\n",
    "    \n",
    "    ax[1][1].grid()\n",
    "    ax[1][1].set_xticks(np.arange(data_rmsprop_val.step.min(), \n",
    "                                  data_rmsprop_val.step.max()+1, 1))\n",
    "    ax[1][1].set_yticks(np.arange(math.floor(data_rmsprop_val.value.min()), 1, 0.02))\n",
    "    ax[1][1].set_ylim([0.1, 0.6])\n",
    "    sns.lineplot(data=data_rmsprop_val, x='step', y='value', hue=hue, ax=ax[1][1], palette='tab10', ci=None)\\\n",
    "        .set_title('Mean of {} for U-Net Model with {} Optimizer (validation) and Band {}'.format(metric, 'rmsprop'.capitalize(), band_title))\n",
    "    ax[1][1].legend(loc='upper left')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7130ddc2",
   "metadata": {},
   "source": [
    "## Plot Accuracy, Binary IoU, Dice Coefficient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d062aeb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "metrics = {'epoch_accuracy': 'Binary Accuracy', \n",
    "           'epoch_binary_iou': 'Binary IoU', \n",
    "           'epoch_dice_coef': 'Dice Coefficient'}\n",
    "\n",
    "# Landsat\n",
    "for key, metric in metrics.items():\n",
    "    plot_metric_for_optimizer(key, 'B4, B3, B2', 'lr', df_landsat_b4_b3_b2)\n",
    "    \n",
    "for key, metric in metrics.items():\n",
    "    plot_metric_for_optimizer(key, 'B7, B5, B2', 'lr', df_landsat_b7_b5_b2)\n",
    "    \n",
    "# Sentinel\n",
    "for key, metric in metrics.items():\n",
    "    plot_metric_for_optimizer(key, 'B4, B3, B2', 'lr', df_sentinel_b4_b3_b2)\n",
    "    \n",
    "for key, metric in metrics.items():\n",
    "    plot_metric_for_optimizer(key, 'B12, B8, B2', 'lr', df_sentinel_b12_b8_b2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4d2cb7d",
   "metadata": {},
   "source": [
    "## Plot Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "428baf11",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "metrics = {'epoch_loss': 'Binary Cross-Entropy'}\n",
    "\n",
    "# Landsat\n",
    "for key, metric in metrics.items():\n",
    "    plot_loss(key, 'B4, B3, B2', 'lr', df_landsat_b4_b3_b2)\n",
    "    \n",
    "for key, metric in metrics.items():\n",
    "    plot_loss(key, 'B7, B5, B2', 'lr', df_landsat_b7_b5_b2) \n",
    "\n",
    "# Sentinel    \n",
    "for key, metric in metrics.items():\n",
    "    plot_loss(key, 'B4, B3, B2', 'lr', df_sentinel_b4_b3_b2)    \n",
    "    \n",
    "for key, metric in metrics.items():\n",
    "    plot_loss(key, 'B12, B8, B2', 'lr', df_sentinel_b12_b8_b2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dbc4995",
   "metadata": {},
   "source": [
    "# Batch Size\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "681c191c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_metric_for_batch(metric, metric_name,band_title, hue, data_for_plot):\n",
    "    data_train= data_for_plot.loc[\n",
    "        (data_for_plot.run.str.endswith('train')) & \n",
    "        (data_for_plot.tag==metric)]\n",
    "    \n",
    "    data_val= data_for_plot.loc[\n",
    "        (data_for_plot.run.str.endswith('validation')) & \n",
    "        (data_for_plot.tag==metric)]\n",
    "    \n",
    "    fig, ax = plt.subplots(nrows=1, ncols=2, figsize=(20, 10), sharey=True)\n",
    "    \n",
    "    ax[0].grid()\n",
    "    ax[0].set_xticks(np.arange(data_train.step.min(), data_train.step.max()+1, 1))\n",
    "    ax[0].set_yticks(np.arange(math.floor(data_train.value.min()), math.floor(data_train.value.max()+1), 0.02))\n",
    "    sns.lineplot(data=data_train, x='step', y='value', hue=hue, ax=ax[0], palette='tab10', ci=None)\\\n",
    "        .set_title('Mean of {} for U-Net Model Using All Batch Size (train) and Band {}'.format(metric_name, band_title))\n",
    "    ax[0].legend(loc='upper left')\n",
    "    \n",
    "    ax[1].grid()\n",
    "    ax[1].set_xticks(np.arange(data_val.step.min(), data_val.step.max()+1, 1))\n",
    "    ax[1].set_yticks(np.arange(math.floor(data_val.value.min()), math.floor(data_val.value.max()+1), 0.02))\n",
    "    sns.lineplot(data=data_val, x='step', y='value', hue=hue, ax=ax[1], palette='tab10', ci=None)\\\n",
    "        .set_title('Mean of {} for U-Net Model Using All Batch Size (validation) and Band {}'.format(metric_name, band_title))\n",
    "    ax[1].legend(loc='upper left')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b12ec9c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_loss_for_batch(metric, metric_name, band_title, hue, data_for_plot):\n",
    "    data_train= data_for_plot.loc[\n",
    "        (data_for_plot.run.str.endswith('train')) & \n",
    "        (data_for_plot.tag==metric)]\n",
    "    \n",
    "    data_val= data_for_plot.loc[\n",
    "        (data_for_plot.run.str.endswith('validation')) & \n",
    "        (data_for_plot.tag==metric)]\n",
    "    \n",
    "    fig, ax = plt.subplots(nrows=1, ncols=2, figsize=(20, 10), sharey=True)\n",
    "    \n",
    "    ax[0].grid()\n",
    "    ax[0].set_xticks(np.arange(data_train.step.min(), data_train.step.max()+1, 1))\n",
    "    ax[0].set_yticks(np.arange(math.floor(data_train.value.min()), 1, 0.02))\n",
    "    ax[0].set_ylim([0.1, 0.6])\n",
    "    sns.lineplot(data=data_train, x='step', y='value', hue=hue, ax=ax[0], palette='tab10', ci=None)\\\n",
    "        .set_title('Mean of {} for U-Net Model Using All Batch Size (train) and Band {}'.format(metric_name, band_title))\n",
    "    ax[0].legend(loc='upper left')\n",
    "    \n",
    "    ax[1].grid()\n",
    "    ax[1].set_xticks(np.arange(data_val.step.min(), data_val.step.max()+1, 1))\n",
    "    ax[1].set_yticks(np.arange(math.floor(data_val.value.min()), 1, 0.02))\n",
    "    ax[1].set_ylim([0.1, 0.6])\n",
    "    sns.lineplot(data=data_val, x='step', y='value', hue=hue, ax=ax[1], palette='tab10', ci=None)\\\n",
    "        .set_title('Mean of {} for U-Net Model Using All Batch Size (validation) and Band {}'.format(metric_name, band_title))\n",
    "    ax[1].legend(loc='upper left')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8de42162",
   "metadata": {},
   "source": [
    "## Plot Accuracy, Binary IoU, Dice Coefficient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23490c50",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "metrics = {'epoch_accuracy': 'Binary Accuracy', \n",
    "           'epoch_binary_iou': 'Binary IoU', \n",
    "           'epoch_dice_coef': 'Dice Coefficient'}\n",
    "\n",
    "hue='run'\n",
    "# Landsat\n",
    "for key, metric in metrics.items():\n",
    "    plot_metric_for_batch(key, metric, 'B4, B3, B2', hue, df_landsat_b4_b3_b2)\n",
    "    \n",
    "for key, metric in metrics.items():\n",
    "    plot_metric_for_batch(key, metric, 'B7, B5, B2', hue, df_landsat_b7_b5_b2)\n",
    "    \n",
    "# Sentinel\n",
    "for key, metric in metrics.items():\n",
    "    plot_metric_for_batch(key, metric, 'B4, B3, B2', hue, df_sentinel_b4_b3_b2)\n",
    "    \n",
    "for key, metric in metrics.items():\n",
    "    plot_metric_for_batch(key, metric, 'B12, B8, B2', hue, df_sentinel_b12_b8_b2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3f401b5",
   "metadata": {},
   "source": [
    "## Plot Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "448911a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = {'epoch_loss': 'Binary Cross-Entropy'}\n",
    "\n",
    "hue='batch'\n",
    "# Landsat\n",
    "for key, metric in metrics.items():\n",
    "    plot_loss_for_batch(key, metric, 'B4, B3, B2', hue, df_landsat_b4_b3_b2)\n",
    "    \n",
    "for key, metric in metrics.items():\n",
    "    plot_loss_for_batch(key, metric, 'B7, B5, B2', hue, df_landsat_b7_b5_b2) \n",
    "\n",
    "# Sentinel    \n",
    "for key, metric in metrics.items():\n",
    "    plot_loss_for_batch(key, metric, 'B4, B3, B2', hue, df_sentinel_b4_b3_b2)    \n",
    "    \n",
    "for key, metric in metrics.items():\n",
    "    plot_loss_for_batch(key, metric,'B12, B8, B2', hue, df_sentinel_b12_b8_b2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07566e58",
   "metadata": {},
   "source": [
    "# Start Filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8541284b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_metric_for_start_filter(metric, metric_name,band_title, hue, data_for_plot):\n",
    "    data_train= data_for_plot.loc[\n",
    "        (data_for_plot.run.str.endswith('train')) & \n",
    "        (data_for_plot.tag==metric)]\n",
    "    \n",
    "    data_val= data_for_plot.loc[\n",
    "        (data_for_plot.run.str.endswith('validation')) & \n",
    "        (data_for_plot.tag==metric)]\n",
    "    \n",
    "    fig, ax = plt.subplots(nrows=1, ncols=2, figsize=(20, 10), sharey=True)\n",
    "    \n",
    "    ax[0].grid()\n",
    "    ax[0].set_xticks(np.arange(data_train.step.min(), data_train.step.max()+1, 1))\n",
    "    ax[0].set_yticks(np.arange(math.floor(data_train.value.min()), math.floor(data_train.value.max()+1), 0.02))\n",
    "    sns.lineplot(data=data_train, x='step', y='value', hue=hue, ax=ax[0], palette='tab10', ci=None)\\\n",
    "        .set_title('Mean of {} for U-Net Model Using All Starting Filter (train) and Band {}'.format(metric_name, band_title))\n",
    "    ax[0].legend(loc='upper left')\n",
    "    \n",
    "    ax[1].grid()\n",
    "    ax[1].set_xticks(np.arange(data_val.step.min(), data_val.step.max()+1, 1))\n",
    "    ax[1].set_yticks(np.arange(math.floor(data_val.value.min()), math.floor(data_val.value.max()+1), 0.02))\n",
    "    sns.lineplot(data=data_val, x='step', y='value', hue=hue, ax=ax[1], palette='tab10', ci=None)\\\n",
    "        .set_title('Mean of {} for U-Net Model Using All Starting Filter (validation) and Band {}'.format(metric_name, band_title))\n",
    "    ax[1].legend(loc='upper left')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a76ae84",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_loss_for_start_filter(metric, metric_name, band_title, hue, data_for_plot):\n",
    "    data_train= data_for_plot.loc[\n",
    "        (data_for_plot.run.str.endswith('train')) & \n",
    "        (data_for_plot.tag==metric)]\n",
    "    \n",
    "    data_val= data_for_plot.loc[\n",
    "        (data_for_plot.run.str.endswith('validation')) & \n",
    "        (data_for_plot.tag==metric)]\n",
    "    \n",
    "    fig, ax = plt.subplots(nrows=1, ncols=2, figsize=(22, 10), sharey=True)\n",
    "    \n",
    "    ax[0].grid()\n",
    "    ax[0].set_xticks(np.arange(data_train.step.min(), data_train.step.max()+1, 1))\n",
    "    ax[0].set_yticks(np.arange(math.floor(data_train.value.min()), 1, 0.02))\n",
    "    ax[0].set_ylim([0.1, 0.6])\n",
    "    sns.lineplot(data=data_train, x='step', y='value', hue=hue, ax=ax[0], palette='tab10', ci=None)\\\n",
    "        .set_title('Mean of {} for U-Net Model Using All Starting Filter (train) and Band {}'.format(metric_name, band_title))\n",
    "    ax[0].legend(loc='upper left')\n",
    "    \n",
    "    ax[1].grid()\n",
    "    ax[1].set_xticks(np.arange(data_val.step.min(), data_val.step.max()+1, 1))\n",
    "    ax[1].set_yticks(np.arange(math.floor(data_val.value.min()), 1, 0.02))\n",
    "    ax[1].set_ylim([0.1, 0.6])\n",
    "    sns.lineplot(data=data_val, x='step', y='value', hue=hue, ax=ax[1], palette='tab10', ci=None)\\\n",
    "        .set_title('Mean of {} for U-Net Model Using All Starting Filter (validation) and Band {}'.format(metric_name, band_title))\n",
    "    ax[1].legend(loc='upper left')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3db92349",
   "metadata": {},
   "source": [
    "## Plot Accuracy, Binary IoU, Dice Coefficient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4fd0589",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = {'epoch_accuracy': 'Binary Accuracy', \n",
    "           'epoch_binary_iou': 'Binary IoU', \n",
    "           'epoch_dice_coef': 'Dice Coefficient'}\n",
    "\n",
    "hue='start_filter'\n",
    "# Landsat\n",
    "for key, metric in metrics.items():\n",
    "    plot_metric_for_start_filter(key, metric, 'B4, B3, B2', hue, df_landsat_b4_b3_b2)\n",
    "    \n",
    "for key, metric in metrics.items():\n",
    "    plot_metric_for_start_filter(key, metric, 'B7, B5, B2', hue, df_landsat_b7_b5_b2)\n",
    "    \n",
    "# Sentinel\n",
    "for key, metric in metrics.items():\n",
    "    plot_metric_for_start_filter(key, metric, 'B4, B3, B2', hue, df_sentinel_b4_b3_b2)\n",
    "    \n",
    "for key, metric in metrics.items():\n",
    "    plot_metric_for_start_filter(key, metric, 'B12, B8, B2', hue, df_sentinel_b12_b8_b2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c57b738a",
   "metadata": {},
   "source": [
    "## Plot Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b4d8cc0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "metrics = {'epoch_loss': 'Binary Cross-Entropy'}\n",
    "\n",
    "hue='start_filter'\n",
    "# Landsat\n",
    "for key, metric in metrics.items():\n",
    "    plot_loss_for_start_filter(key, metric, 'B4, B3, B2', hue, df_landsat_b4_b3_b2)\n",
    "    \n",
    "for key, metric in metrics.items():\n",
    "    plot_loss_for_start_filter(key, metric, 'B7, B5, B2', hue, df_landsat_b7_b5_b2) \n",
    "\n",
    "# Sentinel    \n",
    "for key, metric in metrics.items():\n",
    "    plot_loss_for_start_filter(key, metric, 'B4, B3, B2', hue, df_sentinel_b4_b3_b2)    \n",
    "    \n",
    "for key, metric in metrics.items():\n",
    "    plot_loss_for_start_filter(key, metric,'B12, B8, B2', hue, df_sentinel_b12_b8_b2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c664aaa",
   "metadata": {},
   "source": [
    "# Image Size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "263e1daf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_metric_for_image_size(metric, metric_name,band_title, hue, data_for_plot):\n",
    "    data_train= data_for_plot.loc[\n",
    "        (data_for_plot.run.str.endswith('train')) & \n",
    "        (data_for_plot.tag==metric)]\n",
    "    \n",
    "    data_val= data_for_plot.loc[\n",
    "        (data_for_plot.run.str.endswith('validation')) & \n",
    "        (data_for_plot.tag==metric)]\n",
    "    \n",
    "    fig, ax = plt.subplots(nrows=1, ncols=2, figsize=(20, 10), sharey=True)\n",
    "    \n",
    "    ax[0].grid()\n",
    "    ax[0].set_xticks(np.arange(data_train.step.min(), data_train.step.max()+1, 1))\n",
    "    ax[0].set_yticks(np.arange(math.floor(data_train.value.min()), math.floor(data_train.value.max()+1), 0.02))\n",
    "    sns.lineplot(data=data_train, x='step', y='value', hue=hue, ax=ax[0], palette='tab10', ci=None)\\\n",
    "        .set_title('Mean of {} for U-Net Model Using All Image Size (train) and Band {}'.format(metric_name, band_title))\n",
    "    ax[0].legend(loc='upper left')\n",
    "    \n",
    "    ax[1].grid()\n",
    "    ax[1].set_xticks(np.arange(data_val.step.min(), data_val.step.max()+1, 1))\n",
    "    ax[1].set_yticks(np.arange(math.floor(data_val.value.min()), math.floor(data_val.value.max()+1), 0.02))\n",
    "    sns.lineplot(data=data_val, x='step', y='value', hue=hue, ax=ax[1], palette='tab10', ci=None)\\\n",
    "        .set_title('Mean of {} for U-Net Model Using All Image Size (validation) and Band {}'.format(metric_name, band_title))\n",
    "    ax[1].legend(loc='upper left')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14484860",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_loss_for_image_size(metric, metric_name, band_title, hue, data_for_plot):\n",
    "    data_train= data_for_plot.loc[\n",
    "        (data_for_plot.run.str.endswith('train')) & \n",
    "        (data_for_plot.tag==metric)]\n",
    "    \n",
    "    data_val= data_for_plot.loc[\n",
    "        (data_for_plot.run.str.endswith('validation')) & \n",
    "        (data_for_plot.tag==metric)]\n",
    "    \n",
    "    fig, ax = plt.subplots(nrows=1, ncols=2, figsize=(20, 10), sharey=True)\n",
    "    \n",
    "    ax[0].grid()\n",
    "    ax[0].set_xticks(np.arange(data_train.step.min(), data_train.step.max()+1, 1))\n",
    "    ax[0].set_yticks(np.arange(math.floor(data_train.value.min()), 1, 0.02))\n",
    "    ax[0].set_ylim([0.1, 0.6])\n",
    "    sns.lineplot(data=data_train, x='step', y='value', hue=hue, ax=ax[0], palette='tab10', ci=None)\\\n",
    "        .set_title('Mean of {} for U-Net Model Using All Image Size  (train) and Band {}'.format(metric_name, band_title))\n",
    "    ax[0].legend(loc='upper left')\n",
    "    \n",
    "    ax[1].grid()\n",
    "    ax[1].set_xticks(np.arange(data_val.step.min(), data_val.step.max()+1, 1))\n",
    "    ax[1].set_yticks(np.arange(math.floor(data_val.value.min()), 1, 0.02))\n",
    "    ax[1].set_ylim([0.1, 0.6])\n",
    "    sns.lineplot(data=data_val, x='step', y='value', hue=hue, ax=ax[1], palette='tab10', ci=None)\\\n",
    "        .set_title('Mean of {} for U-Net Model Using All Image Size (validation) and Band {}'.format(metric_name, band_title))\n",
    "    ax[1].legend(loc='upper left')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cedd1150",
   "metadata": {},
   "source": [
    "## Plot Accuracy, Binary IoU, Dice Coefficient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "336a0932",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = {'epoch_accuracy': 'Binary Accuracy', \n",
    "           'epoch_binary_iou': 'Binary IoU', \n",
    "           'epoch_dice_coef': 'Dice Coefficient'}\n",
    "\n",
    "hue='img_size'\n",
    "# Landsat\n",
    "for key, metric in metrics.items():\n",
    "     plot_metric_for_image_size(key, metric, 'B4, B3, B2', hue, df_landsat_b4_b3_b2)\n",
    "    \n",
    "for key, metric in metrics.items():\n",
    "     plot_metric_for_image_size(key, metric, 'B7, B5, B2', hue, df_landsat_b7_b5_b2)\n",
    "    \n",
    "# Sentinel\n",
    "for key, metric in metrics.items():\n",
    "     plot_metric_for_image_size(key, metric, 'B4, B3, B2', hue, df_sentinel_b4_b3_b2)\n",
    "    \n",
    "for key, metric in metrics.items():\n",
    "    plot_metric_for_image_size(key, metric, 'B12, B8, B2', hue, df_sentinel_b12_b8_b2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "893453e1",
   "metadata": {},
   "source": [
    "## Plot Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d1a32bc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "metrics = {'epoch_loss': 'Binary Cross-Entropy'}\n",
    "\n",
    "hue='img_size'\n",
    "# Landsat\n",
    "for key, metric in metrics.items():\n",
    "    plot_loss_for_image_size(key, metric, 'B4, B3, B2', hue, df_landsat_b4_b3_b2)\n",
    "    \n",
    "for key, metric in metrics.items():\n",
    "    plot_loss_for_image_size(key, metric, 'B7, B5, B2', hue, df_landsat_b7_b5_b2) \n",
    "\n",
    "# Sentinel    \n",
    "for key, metric in metrics.items():\n",
    "    plot_loss_for_image_size(key, metric, 'B4, B3, B2', hue, df_sentinel_b4_b3_b2)    \n",
    "    \n",
    "for key, metric in metrics.items():\n",
    "    plot_loss_for_image_size(key, metric,'B12, B8, B2', hue, df_sentinel_b12_b8_b2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e53714eb",
   "metadata": {},
   "source": [
    "# Best Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6510a09",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_landsat_b4_b3_b2 = df.loc[df.satellite_band=='landsat_8_b4_b3_b2']\n",
    "df_sentinel_b4_b3_b2 = df.loc[df.satellite_band=='sentinel_2_b4_b3_b2']\n",
    "df_landsat_b7_b5_b2 = df.loc[df.satellite_band=='landsat_8_b7_b5_b2']\n",
    "df_sentinel_b12_b8_b2 = df.loc[df.satellite_band=='sentinel_2_b12_b8_b2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e18b3331",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_best_model(df):\n",
    "    df_with_max_dice_coef = df.loc[(df.run.str.endswith('\\\\validation'))\n",
    "                                  & (df.tag == 'epoch_dice_coef')].groupby(by=['run'], axis=0).max()\n",
    "    df_with_max_dice_coef.reset_index(inplace=True)\n",
    "\n",
    "    acc_arr = []\n",
    "    binary_iou_arr = []\n",
    "    binary_crossentropy_arr = []\n",
    "    for index, row in df_with_max_dice_coef.iterrows():\n",
    "        temp = df.loc[(df['run'] == row['run']) & (df['step'] == row['step'])]\n",
    "        acc_arr.append(temp.loc[temp['tag']=='epoch_accuracy', 'value'].values[0])\n",
    "        binary_iou_arr.append(temp.loc[temp['tag']=='epoch_binary_iou', 'value'].values[0])    \n",
    "        binary_crossentropy_arr.append(temp.loc[temp['tag']=='epoch_loss', 'value'].values[0])    \n",
    "\n",
    "    # change the column name and drop un-wanted columns\n",
    "    df_with_max_dice_coef.rename(columns={'value':'dice_coefficient'}, inplace=True)\n",
    "    df_with_max_dice_coef.drop(columns=['tag', 'step'], inplace=True)\n",
    "\n",
    "    # adding acc, binary_iou, binary_crossentropy column to the dataframe\n",
    "    df_with_max_dice_coef=df_with_max_dice_coef.assign(acc=acc_arr)\n",
    "    df_with_max_dice_coef=df_with_max_dice_coef.assign(binary_iou=binary_iou_arr)\n",
    "    df_with_max_dice_coef=df_with_max_dice_coef.assign(binary_crossentropy=binary_crossentropy_arr)\n",
    "\n",
    "    cols = [\n",
    "        'run', 'satellite_band', 'opt', 'lr', 'batch', 'start_filter', 'img_size',\n",
    "        'acc', 'binary_iou', 'dice_coefficient', 'binary_crossentropy'\n",
    "    ] \n",
    "    \n",
    "    # find the best model according to each parameter ('opt', 'lr', 'batch', 'start_filter')\n",
    "    temp = df_with_max_dice_coef.groupby(by=['opt', 'lr', 'batch', 'start_filter']).dice_coefficient.max().values\n",
    "    new_df = pd.DataFrame()\n",
    "    for t in temp:\n",
    "        new_df = pd.concat([new_df, df_with_max_dice_coef.loc[df_with_max_dice_coef.dice_coefficient==t]])\n",
    "    return new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9941c2df",
   "metadata": {},
   "outputs": [],
   "source": [
    "## LANDSAT/LC08/C02/T1_TOA (B4, B3, B2)\n",
    "landsat_b4_b3_b2_best_model = find_best_model(df_landsat_b4_b3_b2)\n",
    "## LANDSAT/LC08/C02/T1_TOA (B7, B5, B2)\n",
    "landsat_b7_b5_b2_best_model = find_best_model(df_landsat_b7_b5_b2)\n",
    "\n",
    "## COPERNICUS/S2 (B4, B3, B2)\n",
    "sentinel_b4_b3_b2_best_model = find_best_model(df_sentinel_b4_b3_b2)\n",
    "## COPERNICUS/S2 (B12, B8, B2)\n",
    "sentinel_b12_b8_b2_best_model = find_best_model(df_sentinel_b12_b8_b2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70ec10c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_best_models = pd.DataFrame()\n",
    "\n",
    "max_dice_coef = landsat_b4_b3_b2_best_model.dice_coefficient.max()\n",
    "df_best_models = pd.concat([\n",
    "    df_best_models,                         \n",
    "    landsat_b4_b3_b2_best_model.loc[landsat_b4_b3_b2_best_model['dice_coefficient']==max_dice_coef],\n",
    "])\n",
    "\n",
    "max_dice_coef = landsat_b7_b5_b2_best_model.dice_coefficient.max()\n",
    "df_best_models = pd.concat([\n",
    "    df_best_models, \n",
    "    landsat_b7_b5_b2_best_model.loc[landsat_b7_b5_b2_best_model['dice_coefficient']==max_dice_coef],\n",
    "])\n",
    "\n",
    "max_dice_coef = sentinel_b4_b3_b2_best_model.dice_coefficient.max()\n",
    "df_best_models = pd.concat([\n",
    "    df_best_models, \n",
    "    sentinel_b4_b3_b2_best_model.loc[sentinel_b4_b3_b2_best_model['dice_coefficient']==max_dice_coef],\n",
    "])\n",
    "\n",
    "max_dice_coef = sentinel_b12_b8_b2_best_model.dice_coefficient.max()\n",
    "df_best_models = pd.concat([\n",
    "    df_best_models, \n",
    "    sentinel_b12_b8_b2_best_model.loc[sentinel_b12_b8_b2_best_model['dice_coefficient']==max_dice_coef]\n",
    "])\n",
    "df_best_models.to_csv('best_models.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7779b30a",
   "metadata": {},
   "source": [
    "## Best Model (Landsat) Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cdbca68",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "best_model_landsat_b4_b3_b2_logs = df_landsat_b4_b3_b2.loc[df_landsat_b4_b3_b2['run'] == df_best_models.iloc[0]['run']]\n",
    "best_model_landsat_b7_b5_b2_logs = df_landsat_b7_b5_b2.loc[df_landsat_b7_b5_b2['run'] == df_best_models.iloc[1]['run']]\n",
    "best_model_landsat_logs = pd.concat(\n",
    "    [best_model_landsat_b4_b3_b2_logs,\n",
    "    best_model_landsat_b7_b5_b2_logs],\n",
    "    ignore_index=True,\n",
    ")\n",
    "\n",
    "metrics = {'epoch_accuracy': 'Binary Accuracy', \n",
    "           'epoch_binary_iou': 'Binary IoU', \n",
    "           'epoch_dice_coef': 'Dice Coefficient',\n",
    "           'epoch_loss': 'Binary Cross-Entropy'}\n",
    "\n",
    "for key, metric in metrics.items():\n",
    "    type_run = 'validation'\n",
    "    data = best_model_landsat_logs.loc[\n",
    "        (best_model_landsat_logs.run.str.endswith(type_run)) & \n",
    "        (best_model_landsat_logs.tag==key)]\n",
    "    \n",
    "    plt.figure(figsize=(12, 8))\n",
    "    plt.grid()\n",
    "    plt.xticks(np.arange(data.step.min(), data.step.max()+1, 1))\n",
    "    plt.yticks(np.arange(math.floor(data.value.min()), math.floor(data.value.max()+1), 0.02))\n",
    "    sns.lineplot(data=data, x='step', y='value', hue='run', palette='tab10', ci=None)\\\n",
    "        .set_title('Best U-Net Model (LANDSAT/LC08/C02/T1_TOA) {}'.format(metric))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df38ce14",
   "metadata": {},
   "source": [
    "## Best Model (Sentinel) Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b29ace02",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "best_model_sentinel_b4_b3_b2_logs = df_sentinel_b4_b3_b2.loc[df_sentinel_b4_b3_b2['run'] == df_best_models.iloc[2]['run']]\n",
    "best_model_sentinel_b12_b8_b2_logs = df_sentinel_b12_b8_b2.loc[df_sentinel_b12_b8_b2['run'] == df_best_models.iloc[3]['run']]\n",
    "best_model_sentinel_logs = pd.concat(\n",
    "    [best_model_sentinel_b4_b3_b2_logs,\n",
    "    best_model_sentinel_b12_b8_b2_logs],\n",
    "    ignore_index=True,\n",
    ")\n",
    "\n",
    "metrics = {'epoch_accuracy': 'Binary Accuracy', \n",
    "           'epoch_binary_iou': 'Binary IoU', \n",
    "           'epoch_dice_coef': 'Dice Coefficient',\n",
    "           'epoch_loss': 'Binary Cross-Entropy'}\n",
    "\n",
    "for key, metric in metrics.items():\n",
    "    type_run = 'validation'\n",
    "    data = best_model_sentinel_logs.loc[\n",
    "        (best_model_sentinel_logs.run.str.endswith(type_run)) & \n",
    "        (best_model_sentinel_logs.tag==key)]\n",
    "    \n",
    "    plt.figure(figsize=(12, 8))\n",
    "    plt.grid()\n",
    "    plt.xticks(np.arange(data.step.min(), data.step.max()+1, 1))\n",
    "    plt.yticks(np.arange(math.floor(data.value.min()), math.floor(data.value.max()+1), 0.02))\n",
    "    sns.lineplot(data=data, x='step', y='value', hue='run', palette='tab10', ci=None)\\\n",
    "        .set_title('Best U-Net Model (COPERNICUS/S2) {}'.format(metric))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56dda63f",
   "metadata": {},
   "source": [
    "# 3. Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c493e02b",
   "metadata": {},
   "outputs": [],
   "source": [
    "RANDOM_STATE = 42\n",
    "BATCH_SIZE = 32\n",
    "CHANNEL = 3\n",
    "SEED = RANDOM_STATE\n",
    "AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
    "UNET_MODEL_LANDSAT_8_B4_B3_B2 = landsat_b4_b3_b2_best_model.run.apply(lambda x: x.split('\\\\')[2]).values\n",
    "UNET_MODEL_LANDSAT_8_B7_B5_B2 = landsat_b7_b5_b2_best_model.run.apply(lambda x: x.split('\\\\')[2]).values\n",
    "UNET_MODEL_SENTINEL_2_B4_B3_B2 = sentinel_b4_b3_b2_best_model.run.apply(lambda x: x.split('\\\\')[2]).values\n",
    "UNET_MODEL_SENTINEL_2_B12_B8_B2 = sentinel_b12_b8_b2_best_model.run.apply(lambda x: x.split('\\\\')[2]).values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5db2f1da",
   "metadata": {},
   "source": [
    "# 4. Prepare Functions for Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a005b9ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_tfrecord_fn(example):\n",
    "    \"\"\"\n",
    "    :param example: A scalar string Tensor (a single serialized example)\n",
    "    :return: image and mask data in Tensor form\n",
    "    \"\"\"\n",
    "    feature_description = {\n",
    "        \"image\": tf.io.FixedLenFeature([], tf.string),\n",
    "        \"mask\": tf.io.FixedLenFeature([], tf.string),\n",
    "        \"height\": tf.io.FixedLenFeature([], tf.int64),\n",
    "        \"width\": tf.io.FixedLenFeature([], tf.int64),\n",
    "        \"label\": tf.io.FixedLenFeature([], tf.int64),\n",
    "    }\n",
    "    example = tf.io.parse_single_example(example, feature_description)\n",
    "    \n",
    "    example[\"image\"] = tf.io.decode_png(example[\"image\"])\n",
    "    img_arr = tf.reshape(example[\"image\"], (example[\"height\"], example[\"width\"], CHANNEL))\n",
    "    example[\"mask\"] = tf.io.decode_png(example[\"mask\"])\n",
    "    mask = tf.reshape(example[\"mask\"], (example[\"height\"], example[\"width\"], 1))\n",
    "    \n",
    "    return example[\"image\"], example[\"mask\"], example[\"label\"] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7b45952",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_image_mask(image, mask):\n",
    "    \"\"\"\n",
    "    :param image: image in Tensor form\n",
    "    :param mask: mask in Tensor form\n",
    "    :return: normalized image and mask data in Tensor form\n",
    "    \"\"\"\n",
    "    image = image/255\n",
    "    mask = mask/255\n",
    "    return tf.cast(image, tf.dtypes.float32), tf.cast(mask, tf.dtypes.uint8)\n",
    "\n",
    "def resize_image_mask(image, mask, height, width):\n",
    "    \"\"\"\n",
    "    :param image: image in Tensor form\n",
    "    :param mask: mask in Tensor form\n",
    "    :return: resized image and mask data in Tensor form\n",
    "    \"\"\"\n",
    "    image = tf.image.resize(image, (height, width), method='nearest')\n",
    "    mask = tf.image.resize(mask, (height, width), method='nearest')\n",
    "    return image, mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2064dad8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_test_dataset(dataset_path, height, width):\n",
    "    # return list of tfrecords using glob\n",
    "    files = glob.glob(os.path.join(dataset_path, '*.tfrec'), recursive=False)\n",
    "\n",
    "    # shuffled the filse using random sample \n",
    "    random.seed(SEED)\n",
    "    shuffled_files = random.sample(files, len(files))\n",
    "\n",
    "    # split the shuffled file for train, validation, test\n",
    "    len_dataset = len(shuffled_files)\n",
    "\n",
    "    train_size = math.floor(0.6 * len_dataset)\n",
    "    validation_size = math.ceil(0.2 * len_dataset)\n",
    "    test_size = math.ceil(0.2 * len_dataset)\n",
    "\n",
    "    train_files = shuffled_files[:train_size]\n",
    "    validation_files = shuffled_files[train_size:train_size+validation_size]\n",
    "    test_files = shuffled_files[train_size+validation_size:]\n",
    "\n",
    "    # return a dataset consists of multiple files\n",
    "    parsed_test_dataset = tf.data.TFRecordDataset(test_files, num_parallel_reads=AUTOTUNE).map(parse_tfrecord_fn)\n",
    "    \n",
    "    # resizing and normalization on the test dataset\n",
    "    test_dataset = parsed_test_dataset.map(lambda image, mask, _: resize_image_mask(image, mask, height, width), \n",
    "                                           num_parallel_calls=tf.data.experimental.AUTOTUNE).cache()\n",
    "    test_dataset = test_dataset.map(normalize_image_mask, num_parallel_calls=tf.data.experimental.AUTOTUNE).cache()\n",
    "    test_dataset = test_dataset.batch(1).prefetch(tf.data.experimental.AUTOTUNE)\n",
    "    return test_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fb93bcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dice_coef(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    :param y_true: tensors contain ground truth values\n",
    "    :param y_pred: tensors contain predicted values\n",
    "    :return: dice coefficient value\n",
    "    \"\"\"\n",
    "    X = tf.cast(K.flatten(y_true), tf.dtypes.float32)\n",
    "    Y = tf.cast(K.flatten(y_pred), tf.dtypes.float32)\n",
    "    intersection = K.sum(X * Y)\n",
    "    return 2 * intersection/ (K.sum(X) + K.sum(Y))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec92a52e",
   "metadata": {},
   "source": [
    "\n",
    "# 5. Evaluate U-Net Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c93b2ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(root, unet_model_names, tf_folder_path):\n",
    "    model_paths = []\n",
    "    losses = [] \n",
    "    binary_accuracies = []\n",
    "    dice_coeffs = []\n",
    "    binary_ious = []\n",
    "\n",
    "    for unet_model_name in unet_model_names:\n",
    "        print(unet_model_name)\n",
    "        model_path = os.path.join(root, unet_model_name)\n",
    "        unet_model = tf.keras.models.load_model(model_path, custom_objects={'dice_coef': dice_coef})\n",
    "        config = unet_model.get_config()\n",
    "        _, height, width, _ = config[\"layers\"][0][\"config\"][\"batch_input_shape\"]\n",
    "        print(config[\"layers\"][0][\"config\"][\"batch_input_shape\"])\n",
    "        test_dataset = get_test_dataset(tf_folder_path, height, width)\n",
    "        print(model_path)\n",
    "        score = unet_model.evaluate(test_dataset, verbose = 1)\n",
    "        print('Model Path:', model_path)\n",
    "        print('Test Binary Cross-Entropy Loss:', score[0]) \n",
    "        print('Test Binary Accuracy:', score[1])\n",
    "        print('Test Dice Coefficient:', score[2])\n",
    "        print('Test Binary Intersection Over Union:', score[3]) \n",
    "        model_paths.append(model_path)\n",
    "        losses.append(score[0])\n",
    "        binary_accuracies.append(score[1])\n",
    "        dice_coeffs.append(score[2])\n",
    "        binary_ious.append(score[3])\n",
    "    \n",
    "    return pd.DataFrame({\n",
    "        'model_paths': model_paths,\n",
    "        'binary_crossentropy_loss': losses,\n",
    "        'binary_accuracy': binary_accuracies,\n",
    "        'dice_coefficient': dice_coeffs,\n",
    "        'binary_iou': binary_ious,\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beed6849",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_evaluation = pd.DataFrame()\n",
    "df_evaluation = pd.concat([\n",
    "    df_evaluation, \n",
    "    evaluate_model(\n",
    "        \"models\\\\landsat_8_b4_b3_b2\",\n",
    "        UNET_MODEL_LANDSAT_8_B4_B3_B2,\n",
    "        LANDSAT_8_B4_B3_B2_IMAGE_MASK_TFRECORD_FOLDER_PATH\n",
    ")])\n",
    "\n",
    "df_evaluation = pd.concat([\n",
    "    df_evaluation, \n",
    "    evaluate_model(\n",
    "        \"models\\\\landsat_8_b7_b5_b2\",\n",
    "        UNET_MODEL_LANDSAT_8_B7_B5_B2,\n",
    "        LANDSAT_8_B7_B5_B2_IMAGE_MASK_TFRECORD_FOLDER_PATH\n",
    ")])\n",
    "\n",
    "df_evaluation = pd.concat([\n",
    "    df_evaluation, \n",
    "    evaluate_model(\n",
    "        \"models\\\\sentinel_2_b4_b3_b2\",\n",
    "        UNET_MODEL_SENTINEL_2_B4_B3_B2,\n",
    "        SENTINEL_2_B4_B3_B2_IMAGE_MASK_TFRECORD_FOLDER_PATH\n",
    ")])\n",
    "\n",
    "df_evaluation = pd.concat([\n",
    "    df_evaluation, \n",
    "    evaluate_model(\n",
    "        \"models\\\\sentinel_2_b12_b8_b2\",\n",
    "        UNET_MODEL_SENTINEL_2_B12_B8_B2,\n",
    "        SENTINEL_2_B12_B8_B2_IMAGE_MASK_TFRECORD_FOLDER_PATH\n",
    ")])\n",
    "\n",
    "df_evaluation.to_csv('evaluation.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42dbc8cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_evaluation = pd.read_csv('evaluation.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64d18280",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b33250dc",
   "metadata": {},
   "source": [
    "# Best Models Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d796f6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_prediction(root, unet_model_name, tf_folder_path):\n",
    "    print(unet_model_name)\n",
    "    model_path = os.path.join(root, unet_model_name)\n",
    "    unet_model = tf.keras.models.load_model(model_path, custom_objects={'dice_coef': dice_coef})\n",
    "    config = unet_model.get_config()\n",
    "    _, height, width, _ = config[\"layers\"][0][\"config\"][\"batch_input_shape\"]\n",
    "    print(config[\"layers\"][0][\"config\"][\"batch_input_shape\"])\n",
    "    test_dataset = get_test_dataset(tf_folder_path, height, width)\n",
    "    print(model_path)\n",
    "    result = unet_model.predict(test_dataset, verbose = 1)\n",
    "    return result, test_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b4d5349",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model_landsat_b4_b3_b2_pred, landsat_b4_b3_b2_test_dataset = model_prediction(\"models\\\\landsat_8_b4_b3_b2\",\n",
    "        'unet_model_opt_adam_lr_0.001_batch_16_epochs_20_filters_32_size_176_date_20220809',\n",
    "        LANDSAT_8_B4_B3_B2_IMAGE_MASK_TFRECORD_FOLDER_PATH\n",
    ")\n",
    "\n",
    "best_model_landsat_b7_b5_b2_pred, landsat_b7_b5_b2_test_dataset = model_prediction(\"models\\\\landsat_8_b7_b5_b2\",\n",
    "        'unet_model_opt_adam_lr_0.001_batch_16_epochs_20_filters_32_size_176_date_20220925',\n",
    "        LANDSAT_8_B7_B5_B2_IMAGE_MASK_TFRECORD_FOLDER_PATH\n",
    ")\n",
    "\n",
    "best_model_sentinel_b4_b3_b2_pred, sentinel_b4_b3_b2_test_dataset = model_prediction(\"models\\\\sentinel_2_b4_b3_b2\",\n",
    "        'unet_model_opt_adam_lr_0.001_batch_32_epochs_20_filters_16_size_176_date_20220810',\n",
    "        SENTINEL_2_B4_B3_B2_IMAGE_MASK_TFRECORD_FOLDER_PATH\n",
    ")\n",
    "\n",
    "best_model_sentinel_b12_b8_b2_pred, sentinel_b12_b8_b2_test_dataset = model_prediction(\"models\\\\sentinel_2_b12_b8_b2\",\n",
    "        'unet_model_opt_rmsprop_lr_0.001_batch_16_epochs_20_filters_32_size_144_date_20220924',\n",
    "        SENTINEL_2_B12_B8_B2_IMAGE_MASK_TFRECORD_FOLDER_PATH\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d53cfe1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model_landsat_b4_b3_b2_pred = np.array(best_model_landsat_b4_b3_b2_pred)\n",
    "best_model_landsat_b4_b3_b2_pred = np.where(best_model_landsat_b4_b3_b2_pred<0.5, 0, 1)\n",
    "\n",
    "best_model_landsat_b7_b5_b2_pred = np.array(best_model_landsat_b7_b5_b2_pred)\n",
    "best_model_landsat_b7_b5_b2_pred = np.where(best_model_landsat_b7_b5_b2_pred<0.5, 0, 1)\n",
    "\n",
    "best_model_sentinel_b4_b3_b2_pred = np.array(best_model_sentinel_b4_b3_b2_pred)\n",
    "best_model_sentinel_b4_b3_b2_pred = np.where(best_model_sentinel_b4_b3_b2_pred<0.5, 0, 1)\n",
    "\n",
    "best_model_sentinel_b12_b8_b2_pred = np.array(best_model_sentinel_b12_b8_b2_pred)\n",
    "best_model_sentinel_b12_b8_b2_pred = np.where(best_model_sentinel_b12_b8_b2_pred<0.5, 0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dad3421",
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_image_prediction(dataset, result_mask):\n",
    "    i=0\n",
    "    for batch in dataset.as_numpy_iterator():\n",
    "        if i==5:\n",
    "            break\n",
    "        n_rows = len(batch[0])\n",
    "        n_cols = 3\n",
    "        image = batch[0][0]\n",
    "        true_mask = batch[1][0]\n",
    "        fig, ax = plt.subplots(n_rows, n_cols, figsize=(30, n_rows*10), sharey=True)\n",
    "        ax[0].imshow(image*2)\n",
    "        ax[0].set_title('Image')\n",
    "        ax[1].imshow(true_mask, cmap='gray')\n",
    "        ax[1].set_title('True Mask')\n",
    "        ax[2].imshow(result_mask[i], cmap='gray')\n",
    "        ax[2].set_title('Predicted Mask')\n",
    "        i+=1\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d93a61b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "display_image_prediction(landsat_b4_b3_b2_dataset, best_model_landsat_b4_b3_b2_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82f51b23",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "display_image_prediction(landsat_b7_b5_b2_test_dataset, best_model_landsat_b7_b5_b2_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1aca5d08",
   "metadata": {},
   "outputs": [],
   "source": [
    "display_image_prediction(sentinel_b4_b3_b2_test_dataset, best_model_sentinel_b4_b3_b2_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93e848fe",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "display_image_prediction(sentinel_b12_b8_b2_test_dataset, best_model_sentinel_b12_b8_b2_pred)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sumatera wildfire (pipenv)",
   "language": "python",
   "name": "sumatera-wildfire-classification"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
