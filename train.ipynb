{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6c168228",
   "metadata": {},
   "source": [
    "# U-Net Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f60291d0",
   "metadata": {},
   "source": [
    "# 1. Import All Necessary Libraries and Create File Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fffbf6ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "# Plotting\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Modelling CNN\n",
    "import tensorflow as tf\n",
    "import tensorflow_addons as tfa\n",
    "import glob\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "from sklearn.model_selection import train_test_split\n",
    "import albumentations as A\n",
    "from tqdm import tqdm\n",
    "import math\n",
    "import datetime\n",
    "from keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4606f40e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# folder path or file path constants that will be used in this project\n",
    "# Root Directory (between 'F:' or 'D:'' depends on the external drive)\n",
    "ROOT = \"D:\\\\\"\n",
    "\n",
    "# Folder inside D:\\\\wildfire-sumatera-dataset\n",
    "WILDFIRE_SUMATERA_DATASET_FOLDER_PATH = os.path.join(ROOT, 'wildfire-sumatera-dataset')\n",
    "\n",
    "\n",
    "# Folders and metadatas inside D:\\\\wildfire-sumatera-dataset\n",
    "WILDFIRE_SUMATERA_GEOTIFF_FOLDER_PATH = os.path.join(WILDFIRE_SUMATERA_DATASET_FOLDER_PATH, 'wildfire-sumatera-geotiff')\n",
    "WILDFIRE_SUMATERA_IMAGE_FOLDER_PATH = os.path.join(WILDFIRE_SUMATERA_DATASET_FOLDER_PATH, 'wildfire-sumatera-image')\n",
    "WILDFIRE_SUMATERA_IMAGE_MASK_FOLDER_PATH = os.path.join(WILDFIRE_SUMATERA_DATASET_FOLDER_PATH, 'wildfire-sumatera-image-mask')\n",
    "WILDFIRE_SUMATERA_IMAGE_MASK_TFRECORD_FOLDER_PATH = os.path.join(WILDFIRE_SUMATERA_DATASET_FOLDER_PATH, 'wildfire-sumatera-image-mask-tfrecords')\n",
    "\n",
    "# Files (.csv) and metadatas inside D:\\\\wildfire-sumatera-dataset\n",
    "METADATA_LANDSAT_8_FILE_PATH = os.path.join(WILDFIRE_SUMATERA_DATASET_FOLDER_PATH, 'metadata_landsat_8.csv')\n",
    "METADATA_SENTINEL_2_FILE_PATH = os.path.join(WILDFIRE_SUMATERA_DATASET_FOLDER_PATH, 'metadata_sentinel_2.csv')\n",
    "\n",
    "# Folders inside D:\\\\wildfire-sumatera-dataset\\\\wildfire-sumatera-geotiff\n",
    "SENTINEL_2_GEOTIFF_FOLDER_PATH = os.path.join(WILDFIRE_SUMATERA_GEOTIFF_FOLDER_PATH, 'sentinel-2')\n",
    "LANDSAT_8_GEOTIFF_FOLDER_PATH = os.path.join(WILDFIRE_SUMATERA_GEOTIFF_FOLDER_PATH, 'landsat-8')\n",
    "\n",
    "# Folders inside D:\\\\wildfire-sumatera-dataset\\\\wildfire-sumatera-image\n",
    "SENTINEL_2_IMAGE_FOLDER_PATH = os.path.join(WILDFIRE_SUMATERA_IMAGE_FOLDER_PATH, 'sentinel-2')\n",
    "LANDSAT_8_IMAGE_FOLDER_PATH = os.path.join(WILDFIRE_SUMATERA_IMAGE_FOLDER_PATH, 'landsat-8')\n",
    "\n",
    "# Folders inside D:\\\\wildfire-sumatera-dataset\\\\wildfire-sumatera-geotiff\\\\landsat-8\n",
    "LANDSAT_8_PREFIRE_GEOTIFF_FOLDER_PATH = os.path.join(LANDSAT_8_GEOTIFF_FOLDER_PATH, 'prefire')\n",
    "LANDSAT_8_POSTFIRE_GEOTIFF_FOLDER_PATH = os.path.join(LANDSAT_8_GEOTIFF_FOLDER_PATH, 'postfire')\n",
    "\n",
    "# Folders inside D:\\\\wildfire-sumatera-dataset\\\\wildfire-sumatera-geotiff\\\\sentinel-2\n",
    "SENTINEL_2_PREFIRE_GEOTIFF_FOLDER_PATH = os.path.join(SENTINEL_2_GEOTIFF_FOLDER_PATH, 'prefire')\n",
    "SENTINEL_2_POSTFIRE_GEOTIFF_FOLDER_PATH = os.path.join(SENTINEL_2_GEOTIFF_FOLDER_PATH, 'postfire')\n",
    "\n",
    "# Folders inside D:\\\\wildfire-sumatera-dataset\\\\wildfire-sumatera-image-mask\n",
    "SENTINEL_2_IMAGE_MASK_FOLDER_PATH = os.path.join(WILDFIRE_SUMATERA_IMAGE_MASK_FOLDER_PATH, 'sentinel-2')\n",
    "LANDSAT_8_IMAGE_MASK_FOLDER_PATH = os.path.join(WILDFIRE_SUMATERA_IMAGE_MASK_FOLDER_PATH, 'landsat-8')\n",
    "\n",
    "# Folders inside\n",
    "SENTINEL_2_B12_B8_B2_IMAGE_MASK_TFRECORD_FOLDER_PATH = os.path.join(WILDFIRE_SUMATERA_IMAGE_MASK_TFRECORD_FOLDER_PATH, 'sentinel-2_b12_b8_b2')\n",
    "LANDSAT_8_B7_B5_B2_IMAGE_MASK_TFRECORD_FOLDER_PATH = os.path.join(WILDFIRE_SUMATERA_IMAGE_MASK_TFRECORD_FOLDER_PATH, 'landsat-8_b7_b5_b2')\n",
    "SENTINEL_2_B4_B3_B2_IMAGE_MASK_TFRECORD_FOLDER_PATH = os.path.join(WILDFIRE_SUMATERA_IMAGE_MASK_TFRECORD_FOLDER_PATH, 'sentinel-2_b4_b3_b2')\n",
    "LANDSAT_8_B4_B3_B2_IMAGE_MASK_TFRECORD_FOLDER_PATH = os.path.join(WILDFIRE_SUMATERA_IMAGE_MASK_TFRECORD_FOLDER_PATH, 'landsat-8_b4_b3_b2')\n",
    "\n",
    "\n",
    "dirs = [\n",
    "    WILDFIRE_SUMATERA_DATASET_FOLDER_PATH,\n",
    "    WILDFIRE_SUMATERA_GEOTIFF_FOLDER_PATH, \n",
    "    WILDFIRE_SUMATERA_IMAGE_FOLDER_PATH,\n",
    "    WILDFIRE_SUMATERA_IMAGE_MASK_FOLDER_PATH,\n",
    "    WILDFIRE_SUMATERA_IMAGE_MASK_TFRECORD_FOLDER_PATH,\n",
    "    \n",
    "    SENTINEL_2_GEOTIFF_FOLDER_PATH, \n",
    "    LANDSAT_8_GEOTIFF_FOLDER_PATH,\n",
    "    SENTINEL_2_IMAGE_FOLDER_PATH,\n",
    "    LANDSAT_8_IMAGE_FOLDER_PATH,\n",
    "    \n",
    "    LANDSAT_8_PREFIRE_GEOTIFF_FOLDER_PATH,\n",
    "    LANDSAT_8_POSTFIRE_GEOTIFF_FOLDER_PATH,\n",
    "    SENTINEL_2_PREFIRE_GEOTIFF_FOLDER_PATH,\n",
    "    SENTINEL_2_POSTFIRE_GEOTIFF_FOLDER_PATH,\n",
    "    \n",
    "    SENTINEL_2_IMAGE_MASK_FOLDER_PATH,\n",
    "    LANDSAT_8_IMAGE_MASK_FOLDER_PATH,\n",
    "    \n",
    "    SENTINEL_2_B12_B8_B2_IMAGE_MASK_TFRECORD_FOLDER_PATH,\n",
    "    LANDSAT_8_B7_B5_B2_IMAGE_MASK_TFRECORD_FOLDER_PATH,\n",
    "    SENTINEL_2_B4_B3_B2_IMAGE_MASK_TFRECORD_FOLDER_PATH,\n",
    "    LANDSAT_8_B4_B3_B2_IMAGE_MASK_TFRECORD_FOLDER_PATH,\n",
    "\n",
    "]\n",
    "\n",
    "for dir_ in dirs:\n",
    "    if not os.path.exists(dir_):\n",
    "        os.mkdir(dir_)\n",
    "        print(f\"{dir_} has been created\")\n",
    "    else:\n",
    "        print(f\"{dir_} already exist\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88f21fd2",
   "metadata": {},
   "source": [
    "# 2. Constants\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15f8e791",
   "metadata": {},
   "outputs": [],
   "source": [
    "RANDOM_STATE = 42\n",
    "SEED = RANDOM_STATE\n",
    "LEARNING_RATE = 0.001\n",
    "BATCH_SIZE = 32\n",
    "STARTING_FILTER = 16\n",
    "WIDTH = 176\n",
    "HEIGHT = 176\n",
    "CHANNEL = 3\n",
    "INPUT_SHAPE = (HEIGHT, WIDTH, CHANNEL)\n",
    "OPTIMIZER_NAME = 'adam'\n",
    "AUTOTUNE = tf.data.experimental.AUTOTUNE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06c6ee46",
   "metadata": {},
   "source": [
    "# 3. Prepare Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5398ba39",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_tfrecord_fn(example):\n",
    "    \"\"\"\n",
    "    :param example: A scalar string Tensor (a single serialized example)\n",
    "    :return: image and mask data in Tensor form\n",
    "    \"\"\"\n",
    "    feature_description = {\n",
    "        \"image\": tf.io.FixedLenFeature([], tf.string),\n",
    "        \"mask\": tf.io.FixedLenFeature([], tf.string),\n",
    "        \"height\": tf.io.FixedLenFeature([], tf.int64),\n",
    "        \"width\": tf.io.FixedLenFeature([], tf.int64),\n",
    "        \"label\": tf.io.FixedLenFeature([], tf.int64),\n",
    "    }\n",
    "    example = tf.io.parse_single_example(example, feature_description)\n",
    "    \n",
    "    example[\"image\"] = tf.io.decode_png(example[\"image\"])\n",
    "    img_arr = tf.reshape(example[\"image\"], (example[\"height\"], example[\"width\"], CHANNEL))\n",
    "    example[\"mask\"] = tf.io.decode_png(example[\"mask\"])\n",
    "    mask = tf.reshape(example[\"mask\"], (example[\"height\"], example[\"width\"], 1))\n",
    "    \n",
    "    return example[\"image\"], example[\"mask\"], example[\"label\"] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3626f339",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_shapes(image, mask):\n",
    "    \"\"\"\n",
    "    :param image: image in Tensor form\n",
    "    :param mask: mask in Tensor form\n",
    "    :return: reshaped image and mask data in Tensor form\n",
    "    \"\"\"\n",
    "    image.set_shape(INPUT_SHAPE)\n",
    "    mask.set_shape((WIDTH, HEIGHT, 1))\n",
    "    return image, mask\n",
    "\n",
    "def normalize_image_mask(image, mask):\n",
    "    \"\"\"\n",
    "    :param image: image in Tensor form\n",
    "    :param mask: mask in Tensor form\n",
    "    :return: normalized image and mask data in Tensor form\n",
    "    \"\"\"\n",
    "    image = image/255\n",
    "    mask = mask/255\n",
    "    return tf.cast(image, tf.dtypes.float32), tf.cast(mask, tf.dtypes.uint8)\n",
    "\n",
    "def resize_image_mask(image, mask):\n",
    "    \"\"\"\n",
    "    :param image: image in Tensor form\n",
    "    :param mask: mask in Tensor form\n",
    "    :return: resized image and mask data in Tensor form\n",
    "    \"\"\"\n",
    "    image = tf.image.resize(image, (WIDTH, HEIGHT), method='nearest')\n",
    "    mask = tf.image.resize(mask, (WIDTH, HEIGHT), method='nearest')\n",
    "    return image, mask\n",
    "\n",
    "augmentation = A.Compose([    \n",
    "    A.ShiftScaleRotate(shift_limit=[-0.2, 0.2], \n",
    "                       scale_limit=[-0.2, 0.2], \n",
    "                       rotate_limit=[-90, 90]),\n",
    "    A.OneOf([\n",
    "        A.ElasticTransform(p=0.7),\n",
    "        A.GridDistortion(p=0.7),\n",
    "        A.OpticalDistortion(p=0.7)                  \n",
    "    ]),\n",
    "])\n",
    "\n",
    "    \n",
    "def augment_func(image, mask):\n",
    "    \"\"\"\n",
    "    :param image: image in Tensor form\n",
    "    :param mask: mask in Tensor form\n",
    "    :return: augmented image and mask data in Tensor form\n",
    "    \"\"\"\n",
    "    # resize image and mask\n",
    "    image, mask = resize_image_mask(image, mask)\n",
    "    \n",
    "    # augmentation\n",
    "    data = {\"image\": image.numpy(), 'mask': mask.numpy()}\n",
    "    aug_data = augmentation(**data)\n",
    "    aug_image, aug_mask = aug_data[\"image\"], aug_data[\"mask\"]\n",
    "    \n",
    "    # normalize image and mask\n",
    "    aug_image, aug_mask = normalize_image_mask(aug_image, aug_mask)\n",
    "    return aug_image, aug_mask\n",
    "\n",
    "def process_data(image, mask):\n",
    "    \"\"\"\n",
    "    :param image: image in Tensor form\n",
    "    :param mask: mask in Tensor form\n",
    "    :return: augmented image and mask data in Tensor form\n",
    "    \n",
    "    **info: this function is just a bridge for data augmentation because in order\n",
    "    to do an image augmentation usiing Albumentation, requires a tf.numpy_function.\n",
    "    \"\"\"\n",
    "    aug_image, aug_mask = tf.numpy_function(\n",
    "        func=augment_func, \n",
    "        inp=[image, mask],\n",
    "        Tout=[tf.float32, tf.uint8],\n",
    "    )\n",
    "    return aug_image, aug_mask"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5350fe33",
   "metadata": {},
   "source": [
    "## Using All Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab012d08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# return list of tfrecords using glob\n",
    "files = glob.glob(os.path.join(LANDSAT_8_B7_B5_B2_IMAGE_MASK_TFRECORD_FOLDER_PATH, '*.tfrec'), recursive=False)\n",
    "\n",
    "# shuffled the filse using random sample \n",
    "random.seed(SEED)\n",
    "shuffled_files = random.sample(files, len(files))\n",
    "\n",
    "# split the shuffled file for train, validation, test\n",
    "len_dataset = len(shuffled_files)\n",
    "\n",
    "train_size = math.floor(0.6 * len_dataset)\n",
    "validation_size = math.ceil(0.2 * len_dataset)\n",
    "test_size = math.ceil(0.2 * len_dataset)\n",
    "\n",
    "train_files = shuffled_files[:train_size]\n",
    "validation_files = shuffled_files[train_size:train_size+validation_size]\n",
    "test_files = shuffled_files[train_size+validation_size:]\n",
    "\n",
    "# return a dataset consists of multiple files\n",
    "parsed_train_dataset = tf.data.TFRecordDataset(train_files, num_parallel_reads=AUTOTUNE).map(parse_tfrecord_fn)\n",
    "parsed_validation_dataset = tf.data.TFRecordDataset(validation_files, num_parallel_reads=AUTOTUNE).map(parse_tfrecord_fn)\n",
    "parsed_test_dataset = tf.data.TFRecordDataset(test_files, num_parallel_reads=AUTOTUNE).map(parse_tfrecord_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94d53553",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get all images and masks\n",
    "# image augmentation, resizing and normalization on the train dataset\n",
    "train_dataset = parsed_train_dataset.map(lambda image, mask, _: process_data(image, mask), \n",
    "                                         num_parallel_calls=tf.data.experimental.AUTOTUNE).cache()\n",
    "\n",
    "train_dataset = train_dataset.map(set_shapes, num_parallel_calls=tf.data.experimental.AUTOTUNE) \\\n",
    "                .shuffle(1000) \\\n",
    "                .batch(BATCH_SIZE) \\\n",
    "                .prefetch(tf.data.experimental.AUTOTUNE)\n",
    "\n",
    "# resizing and normalization on the validation dataset\n",
    "validation_dataset = parsed_validation_dataset.map(lambda image, mask, _: resize_image_mask(image, mask), \n",
    "                                                   num_parallel_calls=tf.data.experimental.AUTOTUNE).cache()\n",
    "validation_dataset = validation_dataset.map(normalize_image_mask, num_parallel_calls=tf.data.experimental.AUTOTUNE).cache()\n",
    "validation_dataset = validation_dataset.batch(BATCH_SIZE).prefetch(tf.data.experimental.AUTOTUNE)\n",
    "\n",
    "# resizing and normalization on the test dataset\n",
    "test_dataset = parsed_test_dataset.map(lambda image, mask, _: resize_image_mask(image, mask), \n",
    "                                       num_parallel_calls=tf.data.experimental.AUTOTUNE).cache()\n",
    "test_dataset = test_dataset.map(normalize_image_mask, num_parallel_calls=tf.data.experimental.AUTOTUNE).cache()\n",
    "test_dataset = test_dataset.batch(1).prefetch(tf.data.experimental.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54a01463",
   "metadata": {},
   "outputs": [],
   "source": [
    "for d in train_dataset.take(1):\n",
    "    image = d[0][0].numpy()\n",
    "    mask = d[1][0].numpy()\n",
    "    plt.imshow(image*3)\n",
    "    plt.show()\n",
    "    plt.imshow(mask, cmap='gray')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2dec255",
   "metadata": {},
   "outputs": [],
   "source": [
    "for d in validation_dataset.take(1):\n",
    "    image = d[0][0].numpy()\n",
    "    mask = d[1][0].numpy()\n",
    "    plt.imshow(image*3)\n",
    "    plt.show()\n",
    "    plt.imshow(mask, cmap='gray')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b74a740c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for d in test_dataset.take(1):\n",
    "    image = d[0][0].numpy()\n",
    "    mask = d[1][0].numpy()\n",
    "    plt.imshow(image*3)\n",
    "    plt.show()\n",
    "    plt.imshow(mask, cmap='gray')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ad98ecd",
   "metadata": {},
   "source": [
    "# 3. Get U-Net Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1e31b30",
   "metadata": {},
   "source": [
    "<p align=\"center\">\n",
    "    <img src=\"images/u-net-architecture.png\" alt=\"U-Net Architecture\">\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43d488d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import models.unet_model as unet\n",
    "\n",
    "unet_model_original = unet.get_model(\n",
    "    input_shape=INPUT_SHAPE,\n",
    "    starting_filter=STARTING_FILTER,\n",
    ")\n",
    "display(unet_model_original.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c78c0510",
   "metadata": {},
   "source": [
    "# 4. Prepare metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02a3a0bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dice_coef(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    :param y_true: tensors contain ground truth values\n",
    "    :param y_pred: tensors contain predicted values\n",
    "    :return: dice coefficient value\n",
    "    \"\"\"\n",
    "    X = tf.cast(K.flatten(y_true), tf.dtypes.float32)\n",
    "    Y = tf.cast(K.flatten(y_pred), tf.dtypes.float32)\n",
    "    intersection = K.sum(X * Y)\n",
    "    return 2 * intersection/ (K.sum(X) + K.sum(Y))\n",
    "\n",
    "def jaccard_coef(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    :param y_true: tensors contain ground truth values\n",
    "    :param y_pred: tensors contain predicted values\n",
    "    :return: jaccard coefficient value\n",
    "    \"\"\"\n",
    "    X = tf.cast(K.flatten(y_true), tf.dtypes.float32)\n",
    "    Y = tf.cast(K.flatten(y_pred), tf.dtypes.float32)\n",
    "    intersection = K.sum(X * Y)\n",
    "    union = K.sum(X) + K.sum(Y) - intersection\n",
    "    return intersection/ union"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aad20205",
   "metadata": {},
   "source": [
    "# 5. Compile Model\n",
    "Using:\n",
    "1. Loss Function : Binary Cross Entropy\n",
    "2. Metrics : Binary Accuracy (Accuracy), Dice Coefficient, Binary Intersection over Union (BinaryIoU)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccd1630e",
   "metadata": {},
   "outputs": [],
   "source": [
    "RANDOM_STATE = 42\n",
    "SEED = RANDOM_STATE\n",
    "LEARNING_RATE = 0.001\n",
    "BATCH_SIZE = 32\n",
    "STARTING_FILTER = 16\n",
    "WIDTH = 176\n",
    "HEIGHT = 176\n",
    "CHANNEL = 3\n",
    "INPUT_SHAPE = (HEIGHT, WIDTH, CHANNEL)\n",
    "OPTIMIZER_NAME = 'adam'\n",
    "AUTOTUNE = tf.data.experimental.AUTOTUNE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a02e4033",
   "metadata": {},
   "source": [
    "# 6. Train Using All Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc6a1fbc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Compile Model\n",
    "unet_model = tf.keras.models.clone_model(unet_model_original)\n",
    "\n",
    "if OPTIMIZER_NAME == 'adam':\n",
    "    unet_model.compile(\n",
    "        loss='binary_crossentropy',\n",
    "        optimizer=tf.keras.optimizers.Adam(learning_rate=LEARNING_RATE),\n",
    "        metrics=['accuracy', dice_coef, tf.keras.metrics.BinaryIoU(target_class_ids=[0, 1], threshold=0.5, name=\"binary_iou\")],\n",
    "    )\n",
    "elif OPTIMIZER_NAME == 'rmsprop':\n",
    "    unet_model.compile(\n",
    "        loss='binary_crossentropy',\n",
    "        optimizer=tf.keras.optimizers.RMSprop(learning_rate=LEARNING_RATE),\n",
    "        metrics=['accuracy', dice_coef, tf.keras.metrics.BinaryIoU(target_class_ids=[0, 1], threshold=0.5, name=\"binary_iou\")],\n",
    "    )\n",
    "\n",
    "\n",
    "date = datetime.datetime.now().strftime(\"%Y%m%d\")\n",
    "epochs=20\n",
    "\n",
    "model_path = \"models/landsat_8_b4_b3_b2/unet_model_opt_{}_lr_{}_batch_{}_epochs_{}_filters_{}_size_{}_date_{}\". \\\n",
    "          format(OPTIMIZER_NAME, LEARNING_RATE, BATCH_SIZE, epochs, STARTING_FILTER, INPUT_SHAPE[0], date)\n",
    "\n",
    "log_dir = \"logs_b4_b3_b2/fit/landsat_8_b4_b3_b2/unet_model_opt_{}_lr_{}_batch_{}_epochs_{}_filters_{}_size_{}_date_{}\". \\\n",
    "          format(OPTIMIZER_NAME, LEARNING_RATE, BATCH_SIZE, epochs, STARTING_FILTER, INPUT_SHAPE[0], date)\n",
    "\n",
    "callbacks = [\n",
    "    tf.keras.callbacks.EarlyStopping(monitor = 'val_loss', patience = 5, verbose = 2),\n",
    "    tf.keras.callbacks.ModelCheckpoint(\n",
    "        filepath = model_path, \n",
    "        monitor = 'val_dice_coef', \n",
    "        save_best_only = True,\n",
    "        mode = 'max', \n",
    "        verbose = 2,\n",
    "    ),\n",
    "    tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1),\n",
    "]\n",
    "\n",
    "history = unet_model.fit(\n",
    "    train_dataset,\n",
    "    epochs=epochs,\n",
    "    validation_data=validation_dataset,\n",
    "    callbacks=callbacks,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "223acefa",
   "metadata": {},
   "outputs": [],
   "source": [
    "LEARNING_RATE = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76e82668",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Compile Model\n",
    "unet_model = tf.keras.models.clone_model(unet_model_original)\n",
    "\n",
    "if OPTIMIZER_NAME == 'adam':\n",
    "    unet_model.compile(\n",
    "        loss='binary_crossentropy',\n",
    "        optimizer=tf.keras.optimizers.Adam(learning_rate=LEARNING_RATE),\n",
    "        metrics=['accuracy', dice_coef, tf.keras.metrics.BinaryIoU(target_class_ids=[0, 1], threshold=0.5, name=\"binary_iou\")],\n",
    "    )\n",
    "elif OPTIMIZER_NAME == 'rmsprop':\n",
    "    unet_model.compile(\n",
    "        loss='binary_crossentropy',\n",
    "        optimizer=tf.keras.optimizers.RMSprop(learning_rate=LEARNING_RATE),\n",
    "        metrics=['accuracy', dice_coef, tf.keras.metrics.BinaryIoU(target_class_ids=[0, 1], threshold=0.5, name=\"binary_iou\")],\n",
    "    )\n",
    "\n",
    "\n",
    "date = datetime.datetime.now().strftime(\"%Y%m%d\")\n",
    "epochs=20\n",
    "\n",
    "model_path = \"models/landsat_8_b4_b3_b2/unet_model_opt_{}_lr_{}_batch_{}_epochs_{}_filters_{}_size_{}_date_{}\". \\\n",
    "          format(OPTIMIZER_NAME, LEARNING_RATE, BATCH_SIZE, epochs, STARTING_FILTER, INPUT_SHAPE[0], date)\n",
    "\n",
    "log_dir = \"logs_b4_b3_b2/fit/landsat_8_b4_b3_b2/unet_model_opt_{}_lr_{}_batch_{}_epochs_{}_filters_{}_size_{}_date_{}\". \\\n",
    "          format(OPTIMIZER_NAME, LEARNING_RATE, BATCH_SIZE, epochs, STARTING_FILTER, INPUT_SHAPE[0], date)\n",
    "\n",
    "callbacks = [\n",
    "    tf.keras.callbacks.EarlyStopping(monitor = 'val_loss', patience = 5, verbose = 2),\n",
    "    tf.keras.callbacks.ModelCheckpoint(\n",
    "        filepath = model_path, \n",
    "        monitor = 'val_dice_coef', \n",
    "        save_best_only = True,\n",
    "        mode = 'max', \n",
    "        verbose = 2,\n",
    "    ),\n",
    "    tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1),\n",
    "]\n",
    "\n",
    "history = unet_model.fit(\n",
    "    train_dataset,\n",
    "    epochs=epochs,\n",
    "    validation_data=validation_dataset,\n",
    "    callbacks=callbacks,\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sumatera wildfire (pipenv)",
   "language": "python",
   "name": "sumatera-wildfire-classification"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
